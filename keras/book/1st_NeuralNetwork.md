# Neural Network  


## パーセプトロン  
kerasの単純なモデルはSequentialモデル  
Sequentialモデル: ニューラルネットワークの層を積み上げる。    
```Python
from keras.model import Sequential  
model = Sequential()  
model.add(Dense(12, input_dim=8, kernel_initializer='random_uniform'))  
```
random_uniform: -0.05から0.05の範囲でランダムに初期化  
random_normal: 平均0、分散0.05の正規分布に基づいた初期化  
zero: 全ての重みを0で初期化  


## 多重パーセプトロン  
多重パーセプトロン: 多数の層を持つネットワーク  
ニューラルネットワークは全結合層であり、層内の各ニューロンは、
前の層にある全てのニューロンと次の層の全てのニューロンに接続されていることを意味する。  
パーセプトロンは0か1の変化。  
→ 漸次学習はできない。  
→ 漸次的に変化するシグモイド関数を使用する。  


## 活性化関数  
シグモイド関数:  
入力(-∞,∞)が与えられたとき、(0,1)の範囲で変化する出力を得る。  
数学的にこの関数は連続。  
```math  
\sigma(x) = \frac {1} {1+exp(-x)}  
```  
ReLU関数:  
正規化線形関数  
非線形関数として表す。  
```math  
f(x)=max(0,x)  
```  
以降で、緩やかな変化が、学習アルゴリズムの開発において重要な要素であることを確認する。  
これらの学習アルゴリズムでは、重みを徐々に変化させ、ネットワークの出力誤差を減らすことが求められる。  
[Keras 活性化関数](https://keras.io/ja/activations/)

### 手書き数字認識
MNIST:  
  手書き数字のデータセット  
  6万件の学習データと1万件の評価データ  
  学習データには人手で正解が付与  
  グレースケールで28x28のピクセルで構成される

機械学習では、正解データが付与されたデータセットを利用できる場合、教師あり学習の一形態を適用できる。  
学習データセット → ネットワークをチューニング  
評価データセットをネットワークの学習に使用してはいけない。  

one-hotエンコーディング:


## 勾配降下法  



## 確率的勾配降下法  



